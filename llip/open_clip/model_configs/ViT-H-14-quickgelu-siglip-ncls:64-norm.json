{
    "embed_dim": 1024,
    "num_heads": 8,
    "init_logit_bias": -10,
    "quick_gelu": true,
    "use_norm": true,
    "vision_cfg": {
        "image_size": 224,
        "layers": 32,
        "width": 1280,
        "head_width": 80,
        "patch_size": 14,
        "ncls": 64
    },
    "text_cfg": {
        "context_length": 77,
        "vocab_size": 49408,
        "width": 1024,
        "heads": 16,
        "layers": 24
    }
}
